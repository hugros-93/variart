{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "895a78e48e27132c5d7a6edd994932761e063e4c71477c1b7a9b7172c06f08fc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# vari'art: \n",
    "### Example of latent analysis of a rap clip"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    InputLayer, \n",
    "    Dense, \n",
    "    Reshape, \n",
    "    Flatten, \n",
    "    Dropout, \n",
    "    Conv2D, \n",
    "    Conv2DTranspose, \n",
    "    MaxPool2D,\n",
    "    BatchNormalization\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow_addons.optimizers import Lookahead\n",
    "\n",
    "from variart.preprocessing import ArtVideo\n",
    "from variart.model import VAE\n",
    "from variart.latent import Latent"
   ]
  },
  {
   "source": [
    "## 1. Load data and preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load video\n",
    "name = 'DrillFR4' \n",
    "filename = 'inputs/DrillFR4.mp4'\n",
    "DrillFR4 = ArtVideo(name, filename)\n",
    "DrillFR4.load_video()\n",
    "\n",
    "# Crop images as squares\n",
    "DrillFR4.square()\n",
    "\n",
    "# Resize images\n",
    "size = 64\n",
    "new_shape=(size,size)\n",
    "DrillFR4.resize(new_shape=new_shape)\n",
    "\n",
    "# Rescale pixels in (0,1)\n",
    "DrillFR4.rescale_image()\n",
    "\n",
    "# Input data shape\n",
    "print(f\"Shape {DrillFR4.name}: {DrillFR4.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show randomm image\n",
    "DrillFR4.show_random_image()"
   ]
  },
  {
   "source": [
    "## 2. Train VAE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "data = DrillFR4.X.astype('float32')\n",
    "data = shuffle(data, random_state=0)\n",
    "\n",
    "TRAIN_BUF = int(data.shape[0]*0.9)\n",
    "data_train = data[:TRAIN_BUF]\n",
    "data_validation = data[TRAIN_BUF:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 128\n",
    "epochs = 10000\n",
    "early_stop_patience = 15\n",
    "latent_dim = 8\n",
    "optimizer = Lookahead(Adam(1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(data_train).batch(batch_size)\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices(data_validation).batch(batch_size)\n",
    "nb_features = data.shape[1]*data.shape[2]*data.shape[3]\n",
    "input_shape = (batch_size, data.shape[1], data.shape[2], data.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder and decoder networks (inference and generative)\n",
    "inference_net = tf.keras.Sequential(\n",
    "      [\n",
    "          InputLayer(input_shape=(data.shape[1], data.shape[2], data.shape[3])),\n",
    "          Conv2D(filters=4, kernel_size=3, strides=(1, 1), activation='tanh'),\n",
    "          MaxPool2D((2,2)),\n",
    "          BatchNormalization(),\n",
    "          Conv2D(filters=8, kernel_size=3, strides=(1, 1), activation='tanh'),\n",
    "          MaxPool2D((2,2)),\n",
    "          BatchNormalization(),\n",
    "          Flatten(),\n",
    "          Dense(latent_dim + latent_dim),\n",
    "      ]\n",
    "    )\n",
    "\n",
    "generative_net = tf.keras.Sequential(\n",
    "        [\n",
    "            InputLayer(input_shape=(latent_dim,)),\n",
    "            Dense(units=data.shape[1]*data.shape[2]*4, activation='tanh'),\n",
    "            BatchNormalization(),\n",
    "            Reshape(target_shape=(data.shape[1], data.shape[2], 4)),\n",
    "            Conv2DTranspose(\n",
    "              filters=8,\n",
    "              kernel_size=3,\n",
    "              strides=(1, 1),\n",
    "              padding=\"SAME\",\n",
    "              activation='tanh'),\n",
    "            BatchNormalization(),\n",
    "            Conv2DTranspose(\n",
    "              filters=4,\n",
    "              kernel_size=3,\n",
    "              strides=(1, 1),\n",
    "              padding=\"SAME\",\n",
    "              activation='tanh'),\n",
    "            BatchNormalization(),\n",
    "            Conv2DTranspose(\n",
    "              filters=3, kernel_size=3, strides=(1, 1), padding=\"SAME\"),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "model = VAE(DrillFR4.name, latent_dim, input_shape, inference_net, generative_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "model = model.train(optimizer, \n",
    "                    train_dataset, \n",
    "                    validation_dataset, \n",
    "                    epochs,\n",
    "                    batch_size,\n",
    "                    early_stop_patience = early_stop_patience, \n",
    "                    freq_plot = 25, \n",
    "                    plot_test = True,\n",
    "                    n_to_plot = 4)"
   ]
  },
  {
   "source": [
    "## 3. Latent analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create latent object\n",
    "LatentDrillFR4 = Latent(data, model, scale=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode and decode data\n",
    "LatentDrillFR4.encode_data()\n",
    "LatentDrillFR4.decode_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tsne representation of data in latent space\n",
    "LatentDrillFR4.latent_tsne()\n",
    "LatentDrillFR4.plot_latent_tsne()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute distributions of latent space dimensions\n",
    "LatentDrillFR4.compute_dist_coord()\n",
    "LatentDrillFR4.plot_latent_dist_coord()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform clustering in latent space, test number of cluesters on a grid\n",
    "LatentDrillFR4.latent_space_clustering(grid=range(5,100,5))\n",
    "LatentDrillFR4.plot_silhouette_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select number of clusters\n",
    "n_clusters = 2\n",
    "clusterer = LatentDrillFR4.dico_clust[n_clusters]['clusterer']\n",
    "LatentDrillFR4.plot_latent_tsne(clusterer=clusterer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show images for a given cluster\n",
    "label = 0\n",
    "list_id = [i for i,l in enumerate(clusterer.labels_) if l==label][0:5]\n",
    "LatentDrillFR4.plot_encoded_decoded(list_id=list_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate images by sampling from distributions in the latent space\n",
    "list_z, fig = LatentDrillFR4.generate_image(n=5, method='dist')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GIF from generated images\n",
    "filename = f\"outputs/gif_{LatentDrillFR4.name}.gif\"\n",
    "LatentDrillFR4.create_gif(list_z, filename)"
   ]
  }
 ]
}